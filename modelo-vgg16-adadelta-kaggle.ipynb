{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparación\nSe monta el sistema de archivos de google drive.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.test.gpu_device_name()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-08T19:16:25.159596Z","iopub.execute_input":"2022-01-08T19:16:25.160878Z","iopub.status.idle":"2022-01-08T19:16:31.512897Z","shell.execute_reply.started":"2022-01-08T19:16:25.160709Z","shell.execute_reply":"2022-01-08T19:16:31.512184Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import imshow\nimport numpy as np\nfrom PIL import Image\n\n%matplotlib inline\npil_im = Image.open('../input/flowers-recognition/flowers/daisy/100080576_f52e8ee070_n.jpg', 'r')\nimshow(np.asarray(pil_im))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:16:31.514492Z","iopub.execute_input":"2022-01-08T19:16:31.516107Z","iopub.status.idle":"2022-01-08T19:16:31.790217Z","shell.execute_reply.started":"2022-01-08T19:16:31.516068Z","shell.execute_reply":"2022-01-08T19:16:31.789558Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Carga del dataset","metadata":{}},{"cell_type":"code","source":"image_size = (150, 150)\nbatch_size = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"../input/flowers-recognition/flowers\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"../input/flowers-recognition/flowers\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\n\ntrain_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:16:31.791166Z","iopub.execute_input":"2022-01-08T19:16:31.791409Z","iopub.status.idle":"2022-01-08T19:16:34.061413Z","shell.execute_reply.started":"2022-01-08T19:16:31.791375Z","shell.execute_reply":"2022-01-08T19:16:34.060592Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Modelo","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Rescaling, Flatten, BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:16:34.063611Z","iopub.execute_input":"2022-01-08T19:16:34.063879Z","iopub.status.idle":"2022-01-08T19:16:34.073449Z","shell.execute_reply.started":"2022-01-08T19:16:34.063830Z","shell.execute_reply":"2022-01-08T19:16:34.071376Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(Rescaling(scale=(1./127.5),\n                    offset=-1, \n                    input_shape=(150, 150, 3)))\n\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\n\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding = \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.compile(loss=tf.keras.losses.categorical_crossentropy,\n              optimizer=tf.keras.optimizers.Adadelta(),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:16:34.074763Z","iopub.execute_input":"2022-01-08T19:16:34.075089Z","iopub.status.idle":"2022-01-08T19:16:34.268991Z","shell.execute_reply.started":"2022-01-08T19:16:34.075053Z","shell.execute_reply":"2022-01-08T19:16:34.268325Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Visualización del modelo","metadata":{}},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\n\nplot_model(model, to_file='model_plot.png', show_shapes=True,\n           show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:16:34.270159Z","iopub.execute_input":"2022-01-08T19:16:34.270389Z","iopub.status.idle":"2022-01-08T19:16:35.064523Z","shell.execute_reply.started":"2022-01-08T19:16:34.270355Z","shell.execute_reply":"2022-01-08T19:16:35.063753Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Entrenamiento","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\n\nepochs = 200\n\nes = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=15,\n                   restore_best_weights=True)\n\nh = model.fit(\n        train_ds,\n        epochs=epochs, \n        validation_data=val_ds,\n        callbacks = [es]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:16:35.066124Z","iopub.execute_input":"2022-01-08T19:16:35.066903Z","iopub.status.idle":"2022-01-08T19:28:42.347236Z","shell.execute_reply.started":"2022-01-08T19:16:35.066860Z","shell.execute_reply":"2022-01-08T19:28:42.346517Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Gráfica de evolución de pérdida y exactitud durante el entrenamiento","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.plot(h.history['loss'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['training', 'validation','loss'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:28:42.348444Z","iopub.execute_input":"2022-01-08T19:28:42.348717Z","iopub.status.idle":"2022-01-08T19:28:48.626372Z","shell.execute_reply.started":"2022-01-08T19:28:42.348680Z","shell.execute_reply":"2022-01-08T19:28:48.625662Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Evaluación de los resultados","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\nresults = np.concatenate([(y, model.predict(x=x)) for x, y in val_ds], axis=1)\n\npredictions = np.argmax(results[0], axis=1)\nlabels = np.argmax(results[1], axis=1)\n\ncf_matrix = confusion_matrix(labels, predictions)\n\nsns.heatmap(cf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n\nprint(classification_report(labels, predictions, digits = 4))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:28:48.627874Z","iopub.execute_input":"2022-01-08T19:28:48.628371Z","iopub.status.idle":"2022-01-08T19:28:52.740291Z","shell.execute_reply.started":"2022-01-08T19:28:48.628332Z","shell.execute_reply":"2022-01-08T19:28:52.739605Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n    '../input/flowers-recognition/flowers/daisy/10172636503_21bededa75_n.jpg', target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\n\npredictions = model.predict(img_array)\nprint(np.argmax(predictions[0]))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T19:28:52.742718Z","iopub.execute_input":"2022-01-08T19:28:52.743216Z","iopub.status.idle":"2022-01-08T19:28:52.973706Z","shell.execute_reply.started":"2022-01-08T19:28:52.743178Z","shell.execute_reply":"2022-01-08T19:28:52.972491Z"},"trusted":true},"execution_count":10,"outputs":[]}]}